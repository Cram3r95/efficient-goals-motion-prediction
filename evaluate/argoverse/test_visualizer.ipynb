{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import yaml\n",
    "from prodict import Prodict\n",
    "import torch\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:argoverse.data_loading.vector_map_loader:Loaded root: ArgoverseVectorMap\n",
      "INFO:argoverse.data_loading.vector_map_loader:Loaded root: ArgoverseVectorMap\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = \"/home/denso/carlos_vsr_workspace/mapfe4mp\"\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "import model.datasets.argoverse.dataset_utils as dataset_utils\n",
    "import model.datasets.argoverse.dataset as dataset\n",
    "import model.datasets.argoverse.map_functions as map_functions \n",
    "import model.datasets.argoverse.goal_points_functions as goal_points_functions                                              \n",
    "\n",
    "from argoverse.map_representation.map_api import ArgoverseMap\n",
    "\n",
    "avm = ArgoverseMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = BASE_DIR + \"/config/config_social_lstm_mhsa.yml\"\n",
    "with open(config_dir) as config:\n",
    "    config = yaml.safe_load(config)\n",
    "    config = Prodict.from_dict(config)\n",
    "    config.base_dir = BASE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading .npy files as np data structures ...\n"
     ]
    }
   ],
   "source": [
    "from model.datasets.argoverse.dataset import ArgoverseMotionForecastingDataset, seq_collate\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "config.dataset.path = BASE_DIR + \"/\" + \"data/datasets/argoverse/motion-forecasting/\"\n",
    "\n",
    "config.dataset.split = \"val\"\n",
    "config.dataset.split_percentage = 0.01 # To generate the final results, must be 1 (whole split test)\n",
    "config.dataset.batch_size = 1 # Better to build the h5 results file\n",
    "config.dataset.num_workers = 0\n",
    "config.dataset.class_balance = -1.0 # Do not consider class balance in the split test\n",
    "config.dataset.shuffle = False\n",
    "\n",
    "data_images_folder = config.dataset.path + config.dataset.split + \"/data_images\"\n",
    "\n",
    "data = ArgoverseMotionForecastingDataset(dataset_name=config.dataset_name,\n",
    "                                                 root_folder=config.dataset.path,\n",
    "                                                 obs_len=config.hyperparameters.obs_len,\n",
    "                                                 pred_len=config.hyperparameters.pred_len,\n",
    "                                                 distance_threshold=config.hyperparameters.distance_threshold,\n",
    "                                                 split=config.dataset.split,\n",
    "                                                 split_percentage=config.dataset.split_percentage,\n",
    "                                                 shuffle=config.dataset.shuffle,\n",
    "                                                 class_balance=config.dataset.class_balance,\n",
    "                                                 obs_origin=config.hyperparameters.obs_origin,\n",
    "                                                 preprocess_data=config.dataset.preprocess_data,\n",
    "                                                 save_data=config.dataset.save_data)\n",
    "\n",
    "loader = DataLoader(data,\n",
    "                            batch_size=config.dataset.batch_size,\n",
    "                            shuffle=config.dataset.shuffle,\n",
    "                            num_workers=config.dataset.num_workers,\n",
    "                            collate_fn=seq_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load generator from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrajectoryGenerator(\n",
       "  (encoder): EncoderLSTM(\n",
       "    (encoder): LSTM(2, 256, num_layers=2, bidirectional=True)\n",
       "    (spatial_embedding): Linear(in_features=2, out_features=16, bias=True)\n",
       "  )\n",
       "  (lne): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (sattn): MultiHeadAttention(\n",
       "    (attention): DotProductAttention(\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (W_q): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (W_k): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (W_v): Linear(in_features=256, out_features=256, bias=False)\n",
       "    (W_o): Linear(in_features=256, out_features=256, bias=False)\n",
       "  )\n",
       "  (lnc): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (mlp_decoder_context): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): Linear(in_features=64, out_features=256, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.01)\n",
       "  )\n",
       "  (decoder): TemporalDecoderLSTM(\n",
       "    (decoder): LSTM(16, 256)\n",
       "    (spatial_embedding): Linear(in_features=40, out_features=16, bias=True)\n",
       "    (ln1): LayerNorm((40,), eps=1e-05, elementwise_affine=True)\n",
       "    (hidden2pos): Linear(in_features=256, out_features=2, bias=True)\n",
       "    (ln2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model.models.social_lstm_mhsa import TrajectoryGenerator\n",
    "\n",
    "exp_name = \"social_lstm_mhsa/exp12\"\n",
    "model_path = BASE_DIR + \"/save/argoverse/\" + exp_name + \"/argoverse_motion_forecasting_dataset_0_with_model.pt\"\n",
    "checkpoint = torch.load(model_path)\n",
    "generator = TrajectoryGenerator(h_dim=config.model.generator.encoder_lstm.hdim,\n",
    "                                num_layers=config.model.generator.encoder_lstm.num_layers,\n",
    "                                bidirectional=config.model.generator.encoder_lstm.bidirectional)\n",
    "generator.load_state_dict(checkpoint.config_cp['g_best_state'])\n",
    "generator.cuda() # Use GPU\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_index:  0\n",
      "> \u001b[0;32m/tmp/ipykernel_5993/3900009085.py\u001b[0m(17)\u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     15 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     16 \u001b[0;31m        (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_obj,\n",
      "\u001b[0m\u001b[0;32m---> 17 \u001b[0;31m            loss_mask, seq_start_end, frames, object_cls, obj_id, ego_origin, nsl,_) = batch\n",
      "\u001b[0m\u001b[0;32m     18 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m        \u001b[0mpredicted_traj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from model.datasets.argoverse.dataset_utils import relative_to_abs_sgan\n",
    "\n",
    "num_samples = 5\n",
    "output_all = []\n",
    "\n",
    "ade_list = []\n",
    "fde_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_index, batch in enumerate(loader):\n",
    "        if batch_index > 99:\n",
    "            break\n",
    "        batch = [tensor.cuda() for tensor in batch]\n",
    "        print(\"batch_index: \", batch_index)\n",
    "        pdb.set_trace()\n",
    "        (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_obj,\n",
    "            loss_mask, seq_start_end, frames, object_cls, obj_id, ego_origin, nsl,_) = batch\n",
    "\n",
    "        predicted_traj = []\n",
    "        agent_idx = torch.where(object_cls==1)[0].cpu().numpy()\n",
    "        traj_real = torch.cat([obs_traj, pred_traj_gt], dim=0) + ego_origin.permute(1,0,2)\n",
    "        predicted_traj.append(traj_real[:, agent_idx,:])\n",
    "        #print(agent_idx.shape, agent_idx)\n",
    "        for _ in range(num_samples):\n",
    "            # Get predictions\n",
    "            pred_traj_fake_rel = generator(obs_traj, obs_traj_rel, seq_start_end, agent_idx)\n",
    "\n",
    "            agent_obj_id = obj_id[agent_idx]\n",
    "\n",
    "            # Get predictions in absolute coordinates\n",
    "            pred_traj_fake = relative_to_abs_sgan(pred_traj_fake_rel, obs_traj[-1,agent_idx, :]) # 30,1,2\n",
    "            traj_fake = torch.cat([obs_traj[:,agent_idx, :], pred_traj_fake], dim=0) + ego_origin.permute(1,0,2) # 50,1,2\n",
    "            predicted_traj.append(traj_fake)\n",
    "        \n",
    "        predicted_traj = torch.stack(predicted_traj, axis=0)\n",
    "        predicted_traj = predicted_traj.cpu().numpy()\n",
    "        #if batch_index == 61:\n",
    "        #    print(f\" {batch_index} - {nsl}\")\n",
    "        output_all.append(predicted_traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show qualitative results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/denso/carlos_vsr_workspace/mapfe4mp/evaluate/argoverse/test_visualizer.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B128.32.164.188/home/denso/carlos_vsr_workspace/mapfe4mp/evaluate/argoverse/test_visualizer.ipynb#ch0000011vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B128.32.164.188/home/denso/carlos_vsr_workspace/mapfe4mp/evaluate/argoverse/test_visualizer.ipynb#ch0000011vscode-remote?line=1'>2</a>\u001b[0m ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mgca()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B128.32.164.188/home/denso/carlos_vsr_workspace/mapfe4mp/evaluate/argoverse/test_visualizer.ipynb#ch0000011vscode-remote?line=2'>3</a>\u001b[0m \u001b[39m# 12, 13, 14\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B128.32.164.188/home/denso/carlos_vsr_workspace/mapfe4mp/evaluate/argoverse/test_visualizer.ipynb#ch0000011vscode-remote?line=4'>5</a>\u001b[0m file_id \u001b[39m=\u001b[39m \u001b[39m73\u001b[39m \u001b[39m# From 1 to N files in the split\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "ax = plt.gca()\n",
    "# 12, 13, 14\n",
    "\n",
    "file_id = 73 # From 1 to N files in the split\n",
    "\n",
    "predicted_traj = output_all[file_id-1] \n",
    "\n",
    "# Validation\n",
    "\n",
    "## Good example: 95\n",
    "## Very challenging: 71\n",
    "## Almost impossible:\n",
    "\n",
    "# Train\n",
    "\n",
    "## Good example:\n",
    "## Very challenging:\n",
    "## Almost impossible: 6\n",
    "\n",
    "# filename = data_images_folder + \"/\" + str(file_id) + \".png\"\n",
    "\n",
    "# img = cv2.imread(filename)\n",
    "# img = cv2.resize(img, dsize=(600,600))\n",
    "\n",
    "print(\"predicted_traj \", predicted_traj.shape)\n",
    "with plt.rc_context({'xtick.color': 'white', 'ytick.color': 'white'}):\n",
    "    plt.grid(linestyle='-', linewidth=2)\n",
    "    plt.plot(predicted_traj[0,0,0,0],predicted_traj[0,0,0,1],'-o',c='r') #starting point here\n",
    "    plt.plot(predicted_traj[0,:21,:,0],predicted_traj[0,:21,:,1],'*',c='b')\n",
    "\n",
    "    for i in range(predicted_traj.shape[0]):\n",
    "        if i == 0:\n",
    "            c = 'black'\n",
    "        else:\n",
    "            c= np.random.rand(3,)\n",
    "        plt.plot(predicted_traj[i,20:,:,0],predicted_traj[i,20:,:,1],'*',c=c)#np.random.rand(3,)\n",
    "    plt.xlabel('map_x_coord (m)')\n",
    "    plt.ylabel('map_y_coord (m)')\n",
    "    \n",
    "    #plt.imshow(img)\n",
    "    \n",
    "    ax.set_aspect('equal')\n",
    "    ax.figure.set_size_inches(10,10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('carlos_vsr_mapfe4mp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "23ec5f46142f59639cbc0610b784427ad5a7b29b5f6f786971843ba12bc604ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
